import openai
import matplotlib.pyplot as plt
from openpyxl import load_workbook
import os
import csv  # æ”¾åœ¨æ–‡ä»¶å¼€å¤´


########################
# ç¬¬ 1 éƒ¨åˆ†ï¼šLLM è¯„ä¼°å‡½æ•°
########################

def judge_replies(reply_a: str, reply_b: str) -> str:
    """
    å¯¹æ¯” reply_a, reply_bï¼Œè°ƒç”¨è¯„ä¼°ç”¨çš„ LLM è¿”å›:
    - "model1"  (è¡¨ç¤º A æ›´å¥½)
    - "model2"  (è¡¨ç¤º B æ›´å¥½)
    - "tie"     (è¡¨ç¤º å·®ä¸å¤š)
    """

    # è¿™é‡Œæ›¿æ¢æˆä½ è‡ªå·±çš„ API Key æˆ–è€…è°ƒç”¨ç§æœ‰ LLM çš„æ¥å£
    # openai.api_key = "YOUR_OPENAI_API_KEY"
    openai.api_key = os.environ.get("OPENAI_API_KEY")
    if openai.api_key is None:
        raise ValueError("âŒ Environment variable 'OPENAI_API_KEY' not found. Please export it in your terminal.")


    # ç»™è¯„ä¼°æ¨¡å‹çš„æç¤ºè¯ï¼Œå¯æ ¹æ®éœ€æ±‚æ”¹åŠ¨
    system_prompt = """You are an unbiased judge. 
You will be provided with two email replies (Reply A and Reply B). 
You must compare them in terms of clarity, correctness, completeness, politeness, and overall helpfulness. 
Output one single token among these:
- "model1": if Reply A is clearly better,
- "model2": if Reply B is clearly better,
- "tie": if they are about the same quality.
Do not explain your reasoning. Just return one word exactly: model1, model2, or tie.
"""
    user_prompt = f"""
Reply A:
{reply_a}

Reply B:
{reply_b}

Which reply is better?
"""
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",  # æˆ– "gpt-3.5-turbo" / ä½ è‡ªå·±éƒ¨ç½²çš„æ¨¡å‹
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user",   "content": user_prompt},
            ],
            temperature=0.0
        )
        content = response["choices"][0]["message"]["content"].strip().lower()
        if content in ["model1", "model2", "tie"]:
            return content
        else:
            return "tie"
    except Exception as e:
        print("Error calling LLM:", e)
        # å¦‚æœå‡ºé”™å°±é»˜è®¤è®¾ä¸º tieï¼Œæˆ–æ ¹æ®éœ€è¦æ”¹æˆå…¶å®ƒé€»è¾‘
        return "tie"

########################
# ç¬¬ 2 éƒ¨åˆ†ï¼šExcel æ•°æ®è¯»å– & ä¸¤ä¸¤å¯¹æ¯”
########################

# def compare_two_columns(
#     workbook_path: str,
#     col_a: int,
#     col_b: int,
#     skip_header: bool = True,
#     judge_func=judge_replies,
# ) -> dict:
#     """
#     ä» Excel ä¸­è¯»å–ä¸¤åˆ—æ•°æ® (åˆ—å·ä»1å¼€å§‹)ï¼Œ
#     è°ƒç”¨ judge_func() è¿›è¡Œå¯¹æ¯”ï¼Œç»Ÿè®¡ modelAèƒœ / modelBèƒœ / tie çš„æ¬¡æ•°ã€‚
    
#     è¿”å›å½¢å¦‚: {"model1": x, "model2": y, "tie": z, "total": n}
#     """
#     wb = load_workbook(workbook_path)
#     sheet = wb.active
#     rows = list(sheet.iter_rows(values_only=True))

#     if skip_header:
#         rows = rows[1:]  # è·³è¿‡è¡¨å¤´è¡Œ

#     score_model1 = 0
#     score_model2 = 0
#     score_tie = 0
#     total_count = 0

#     for row in rows:
#         # row æ˜¯ä¸€ä¸ªå…ƒç»„ï¼Œæ¯ä¸ªå…ƒç´ å¯¹åº”ä¸€åˆ—çš„å€¼
#         # Excel ä¸­åˆ—å· col_a, col_b æ˜¯ä»1å¼€å§‹ï¼Œä½† Python ä¸‹æ ‡ä»0å¼€å§‹ï¼Œæ‰€ä»¥è¦ col_a-1
#         reply_a = row[col_a - 1] if len(row) >= col_a else None
#         reply_b = row[col_b - 1] if len(row) >= col_b else None
#         # å¦‚æœå…¶ä¸­ä¸€ä¸ªä¸ºç©ºï¼Œå°±è·³è¿‡
#         if not reply_a or not reply_b:
#             continue
#         print(f"\nğŸ” Comparing pair #{total_count + 1}")
#         print(f"--- Reply A (Model1):\n{reply_a}")
#         print(f"--- Reply B (Model2):\n{reply_b}")
#         total_count += 1
#         result = judge_func(reply_a, reply_b)
#         if result == "model1":
#             score_model1 += 1
#         elif result == "model2":
#             score_model2 += 1
#         else:
#             score_tie += 1

#     return {
#         "model1": score_model1,
#         "model2": score_model2,
#         "tie": score_tie,
#         "total": total_count,
#     }

def compare_two_columns(
    workbook_path: str,
    col_a: int,
    col_b: int,
    skip_header: bool = True,
    judge_func=judge_replies,
    log_path: str = None,
    label: str = None
) -> dict:
    """
    ä» Excel ä¸­è¯»å–ä¸¤åˆ—æ•°æ® (åˆ—å·ä»1å¼€å§‹)ï¼Œ
    è°ƒç”¨ judge_func() è¿›è¡Œå¯¹æ¯”ï¼Œç»Ÿè®¡ modelAèƒœ / modelBèƒœ / tie çš„æ¬¡æ•°ã€‚
    å¯é€‰ï¼šå°†æ¯ä¸€æ¡å¯¹æ¯”å†™å…¥ log æ–‡ä»¶ã€‚
    """
    wb = load_workbook(workbook_path)
    sheet = wb.active
    rows = list(sheet.iter_rows(values_only=True))
    if skip_header:
        rows = rows[1:]

    score_model1 = 0
    score_model2 = 0
    score_tie = 0
    total_count = 0

    logs = []

    for idx, row in enumerate(rows):
        reply_a = row[col_a - 1] if len(row) >= col_a else None
        reply_b = row[col_b - 1] if len(row) >= col_b else None
        if not reply_a or not reply_b:
            continue
        total_count += 1
        result = judge_func(reply_a, reply_b)
        if result == "model1":
            score_model1 += 1
        elif result == "model2":
            score_model2 += 1
        else:
            score_tie += 1

        # <<< æ·»åŠ æ—¥å¿— >>>
        logs.append({
            "Index": idx + 2 if skip_header else idx + 1,
            "Reply A": reply_a,
            "Reply B": reply_b,
            "Result": result
        })

    # <<< å†™å…¥æ—¥å¿—åˆ° CSV >>>
    if log_path and label:
        filename = f"{log_path}/comparison_log_{label.replace(' ', '_')}.csv"
        with open(filename, mode="w", encoding="utf-8-sig", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=["Index", "Reply A", "Reply B", "Result"])
            writer.writeheader()
            writer.writerows(logs)
        print(f"ğŸ” Log saved to {filename}")

    return {
        "model1": score_model1,
        "model2": score_model2,
        "tie": score_tie,
        "total": total_count,
    }
    
########################
# ç¬¬ 3 éƒ¨åˆ†ï¼šå¯è§†åŒ– - ç”»å †å æŸ±çŠ¶å›¾
########################

def create_stacked_bar_chart(results_list: list, title: str = "Human Evaluation"):
    """
    ç»™å®šè‹¥å¹²ç»„å¯¹æ¯”ç»“æœï¼Œç”»å‡ºå †å æŸ±çŠ¶å›¾ï¼Œæ¯ç»„æ˜¾ç¤º model1_win, tie, model2_win ä¸‰æ®µã€‚
    
    results_list å½¢å¦‚ï¼š
    [
      {
        "label": "ModelA vs ModelB",
        "model1": 10,
        "model2": 5,
        "tie": 2,
        "total": 17
      },
      {
        "label": "ModelC vs ModelD",
        "model1": 8,
        "model2": 8,
        "tie": 4,
        "total": 20
      },
      ...
    ]
    """
    labels = [r["label"] for r in results_list]
    # è®¡ç®—ç™¾åˆ†æ¯”
    model1_pct = []
    tie_pct = []
    model2_pct = []
    for r in results_list:
        total = r["total"]
        if total == 0:
            model1_pct.append(0)
            tie_pct.append(0)
            model2_pct.append(0)
        else:
            model1_pct.append(r["model1"] / total * 100)
            tie_pct.append(r["tie"] / total * 100)
            model2_pct.append(r["model2"] / total * 100)

    x = range(len(labels))  # x è½´æ¯ä¸€ç»„ä½ç½®
    fig, ax = plt.subplots(figsize=(8, 4))

    # ç”»ä¸‰æ®µå †å : model1_win åœ¨æœ€åº•å±‚ï¼Œtie åœ¨ä¸Šé¢ï¼Œmodel2_win åœ¨æœ€ä¸Šé¢
    bar1 = ax.barh(x, model1_pct, color='teal', label='Win (Model1)')
    bar2 = ax.barh(x, tie_pct, left=model1_pct, color='gray', label='Tie')
    # è¿™é‡Œçš„ left= éœ€è¦æ˜¯ model1_pct + tie_pct çš„ç´¯ç§¯
    # ä½† barh() åªè®¤å…·ä½“æ•°å€¼è€Œéåˆ—è¡¨é—´åŠ æ³•ï¼Œæ‰€ä»¥å¾—å…ˆæŠŠå®ƒä»¬åŠ èµ·æ¥
    left_for_model2 = [m1 + t for m1, t in zip(model1_pct, tie_pct)]
    bar3 = ax.barh(x, model2_pct, left=left_for_model2, color='red', label='Win (Model2)')

    # åœ¨æ¯æ®µæ¡å½¢ä¸ŠåŠ ä¸Šæ•°å€¼
    def add_labels(bar_obj, base_list):
        for rect, base_val in zip(bar_obj, base_list):
            width = rect.get_width()
            if width > 0:
                # æ˜¾ç¤ºåœ¨åŒºæ®µä¸­é—´
                x_pos = base_val + width / 2
                y_pos = rect.get_y() + rect.get_height() / 2
                ax.text(x_pos, y_pos, f"{width:.1f}%", ha='center', va='center', color='white', fontsize=9)
    
    add_labels(bar1, [0]*len(model1_pct))
    add_labels(bar2, model1_pct)
    add_labels(bar3, left_for_model2)

    ax.set_yticks(x)
    ax.set_yticklabels(labels)
    ax.set_xlabel("% win rate")
    ax.set_xlim([0, 100])
    ax.set_title(title)
    ax.invert_yaxis()  # è®©æœ€ä¸Šé¢ä¸€ç»„åœ¨å›¾ä¸Šç«¯ï¼Œå¯æ ¹æ®å®¡ç¾å†³å®šæ˜¯å¦ invert
    ax.legend(loc="lower right")
    plt.tight_layout()
    plt.show()

########################
# ç¬¬ 4 éƒ¨åˆ†ï¼šç¤ºä¾‹ä¸»å‡½æ•° - è‡ªå®šä¹‰éœ€è¦æ¯”è¾ƒçš„ã€Œåˆ—å¯¹ã€
########################

def main():
    workbook_path = "results.xlsx"
    
    # è¿™é‡Œå®šä¹‰è‹¥å¹²è¦å¯¹æ¯”çš„â€œåˆ—å¯¹â€ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ (name, colA, colB)
    # æ³¨ï¼šåˆ—å·ä» 1 å¼€å§‹æ•°ï¼Œå¦‚ï¼š1 = Aåˆ—, 2 = Båˆ—, 3 = Cåˆ—, 4 = Dåˆ—, ...
    pairs_to_compare = [
        ("local Llama3.2-3b vs GPT-4", 2, 5),  # Dåˆ— vs Eåˆ— (ç¤ºä¾‹)
        ("someModel vs anotherModel", 2, 3),  # Båˆ— vs Cåˆ— (ä¸¾ä¾‹)
        # ä½ ä¹Ÿå¯ä»¥æ·»åŠ æ›´å¤šï¼Œå¦‚ ("ModelX vs ModelY", 6, 7) ...
    ]
    
    results_for_chart = []
    
    for pair_label, colA, colB in pairs_to_compare:
        # comparison = compare_two_columns(
        #     workbook_path=workbook_path,
        #     col_a=colA,
        #     col_b=colB,
        #     skip_header=True,
        #     judge_func=judge_replies
        # )
        
        comparison = compare_two_columns(
            workbook_path=workbook_path,
            col_a=colA,
            col_b=colB,
            skip_header=True,
            judge_func=judge_replies,
            log_path="logs",              # ä½ æƒ³å­˜æ—¥å¿—çš„æ–‡ä»¶å¤¹
            label=pair_label              # ç”¨æ¥å‘½åæ—¥å¿—æ–‡ä»¶
        )
        
        # æŠŠå¯¹æ¯”ç»“æœæ±‡æ€»åˆ°ä¸€ä¸ªå­—å…¸é‡Œï¼Œç”¨äºåé¢ç»˜å›¾
        results_for_chart.append({
            "label": pair_label,
            "model1": comparison["model1"],
            "model2": comparison["model2"],
            "tie": comparison["tie"],
            "total": comparison["total"],
        })
    
    # ç»˜åˆ¶å †å æŸ±çŠ¶å›¾
    create_stacked_bar_chart(results_for_chart, title="Pairwise Comparison Results")

if __name__ == "__main__":
    main()
